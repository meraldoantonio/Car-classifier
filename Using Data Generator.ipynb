{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For folder processing\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# For Image Processing and Display\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# For Visualization\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "from jupyter_plotly_dash import JupyterDash\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# For data processing\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Training Image Classification Model\n",
    "import keras\n",
    "import os.path\n",
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\n",
    "import shutil\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_dataset(url, target_folder):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        - Creates a subdirectory \"./Data\" in the current working directory if it doesn't exist already\n",
    "        - Downloads the dataset into the newly created folder\n",
    "        \n",
    "    Arguments:\n",
    "        - url: (str) URL of dataset\n",
    "        - target_folder: (str) relative path of target folder\n",
    "        \n",
    "    Return:\n",
    "        - A \"./Data\" folder containing the zipped dataset\n",
    "    \"\"\"\n",
    "    # Path to downloaded file\n",
    "    target_file = target_folder + \"/\" + url.split(\"/\")[-1]\n",
    "    \n",
    "    # If the dataset has already been downloaded, terminate function\n",
    "    if os.path.exists(target_file):\n",
    "        print(\"Data has already been downloaded at '{}'.\".format(target_file))\n",
    "        return\n",
    "    \n",
    "    # If target folder doesn't exist yet, create it\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.mkdir(target_folder.split(\"/\")[-1])\n",
    "        print(\"Created a new folder at '{}'.\".format(target_folder))\n",
    "        \n",
    "    # Downloading the dataset\n",
    "    print(\"Downloading dataset from '{}', please wait...\".format(url))\n",
    "    urllib.request.urlretrieve(url, target_file)  \n",
    "    print(\"File successfully downloaded to '{}''.\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"http://imagenet.stanford.edu/internal/car196/cars_train.tgz\" \n",
    "target_folder = \"./data\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matlab file conntaining that maps the label and full name of the car\n",
    "original_dict_metadata = loadmat('devkit/cars_meta.mat')\n",
    "#dict_meta = dictionary containing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_idx_carname = {int(index+1):classname[0] for index, classname in enumerate(original_dict_metadata[\"class_names\"][0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matlab file\n",
    "original_dict_traindata = loadmat('devkit/cars_train_annos.mat')\n",
    "\n",
    "master_dict_traindata = {}\n",
    "# Annotations = {\"fname\": {\"bbox_xmin\": 12, \"bbox_xmax\": 13, \"bbox_y1\": , \"bbox_y2\"}}\n",
    "\n",
    "master_dict_traindata = {image[5][0]:{\"bbox_xmin\": image[0][0][0], \"bbox_xmin\": image[0][0][0], \"bbox_xmax\": image[1][0][0],\"bbox_ymin\": image[2][0][0],\"bbox_ymax\": image[3][0][0],\"classnumber\": image[4][0][0], \"classname\": dict_idx_carname[image[4][0][0]]} for image in original_dict_traindata[\"annotations\"][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(data = master_dict_traindata, orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_valid = train_test_split(df, train_size = 0.9, random_state = 88, stratify = df.classnumber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_subfolders():\n",
    "    \n",
    "    # Creation of train and valid subfolder\n",
    "    folders = [\"train\", \"valid\"]\n",
    "    for folder in folders:\n",
    "        if not os.path.exists(path +\"/\"+ folder):\n",
    "            os.makedirs(path +\"/\"+ folder)\n",
    "    \n",
    "    # Creation of car subfolders\n",
    "    for folder in folders:\n",
    "        for carname in dict_idx_carname.values():\n",
    "            if not os.path.exists(path + \"/\"+ folder + \"/\"+ carname):\n",
    "                os.makedirs(path +\"/\"+ folder + \"/\" + carname)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting image to its own folder\n",
    "def sort_images_to_subfolders():\n",
    "    for folder in folders:\n",
    "        if folder == \"train\":\n",
    "            df_focus = df_train\n",
    "        else:\n",
    "            df_focus = df_valid\n",
    "        for image_filename in df_focus.index:\n",
    "            carname = df_focus.loc[image_filename, \"classname\"]\n",
    "\n",
    "            source_path_complete = \"./data\" + \"/\" + image_filename\n",
    "            destination_path_complete = path + \"/\" + folder + \"/\" + carname + \"/\" + image_filename\n",
    "            shutil.move(source_path_complete, destination_path_complete)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_untrained_transfer_model():\n",
    "    \"\"\"\n",
    "    If model isn't saved - download model, save it to current directory and return it\n",
    "    If model already exists, simply return the model\n",
    "    \"\"\"\n",
    "    model_path = \"./model/Untrained_transfer.h5\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Retrieving saved model from {model_path}\")\n",
    "        untrained_transfer_model = load_model(model_path)\n",
    "        print(\"Saved model retrieved!\")\n",
    "        return untrained_transfer_model\n",
    "    else:\n",
    "        ## Build model\n",
    "        print(\"Downloading and building model...\")\n",
    "        untrained_transfer_model = Sequential()\n",
    "        untrained_transfer_model.add(ResNet50(include_top = False, pooling = \"avg\", weights = \"imagenet\"))\n",
    "        untrained_transfer_model.add(Dense(512, activation = \"relu\"))\n",
    "        untrained_transfer_model.add(Dropout(0.5))\n",
    "        untrained_transfer_model.add(Dense(512, activation = \"relu\"))\n",
    "        untrained_transfer_model.add(Dropout(0.5))\n",
    "        untrained_transfer_model.add(Dense(196, activation = \"softmax\"))\n",
    "        \n",
    "        untrained_transfer_model.layers[0].trainable = False\n",
    "        \n",
    "        ## Save model\n",
    "        print(f\"Model built and saved in {model_path}\")\n",
    "        untrained_transfer_model.save(model_path)\n",
    "        return untrained_transfer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving saved model from ./model/Untrained_transfer.h5\n",
      "WARNING:tensorflow:From /home/meraldoantonio/anaconda3/envs/grabenv/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/meraldoantonio/anaconda3/envs/grabenv/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Saved model retrieved!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meraldoantonio/anaconda3/envs/grabenv/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning:\n",
      "\n",
      "No training configuration found in save file: the model was *not* compiled. Compile it manually.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transfer_model = load_untrained_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 196)               100548    \n",
      "=================================================================\n",
      "Total params: 25,000,004\n",
      "Trainable params: 24,946,884\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7329"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(np_image):\n",
    "    resized_np_image = np.resize(np_image,(224,224,3))\n",
    "    preprocessed_np_image = preprocess_input(resized_np_image)\n",
    "    return preprocessed_np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[\"preprocessed_np_image\"] = df_train[\"np_image\"].apply(lambda x: preprocess_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = './data2/train'\n",
    "valid_data = './data2/valid'\n",
    "n_train_samples = df_train.shape[0]\n",
    "n_valid_samples = df_valid.shape[0]\n",
    "verbose = 1\n",
    "batch_size = 16\n",
    "n_epochs = 5\n",
    "patience = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ImageDataGenerator = ImageDataGenerator(rotation_range=20.,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    preprocessing_function = preprocess_image)\n",
    "\n",
    "\n",
    "valid_ImageDataGenerator = ImageDataGenerator(preprocessing_function = preprocess_image)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7329 images belonging to 196 classes.\n",
      "Found 815 images belonging to 196 classes.\n"
     ]
    }
   ],
   "source": [
    "# generators\n",
    "train_generator = train_ImageDataGenerator.flow_from_directory(train_data, (224, 224), batch_size=batch_size,\n",
    "                                                     class_mode='categorical')\n",
    "valid_generator = valid_ImageDataGenerator.flow_from_directory(valid_data, (224, 224), batch_size=batch_size,\n",
    "                                                     class_mode='categorical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger, ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define callbacks\n",
    "tensor_board = TensorBoard(log_dir='./logs', histogram_freq=0, write_graph=True, write_images=True)\n",
    "\n",
    "log_file_path = 'logs/training.log'\n",
    "csv_logger = CSVLogger(log_file_path, append=False)\n",
    "\n",
    "early_stop = EarlyStopping('val_acc', patience=patience)\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau('val_acc', factor=0.1, patience=int(patience / 4), verbose=1)\n",
    "\n",
    "trained_models_path = 'model/model'\n",
    "model_names = trained_models_path + '.{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "model_checkpoint = ModelCheckpoint(model_names, monitor='val_acc', verbose=1, save_best_only=True)\n",
    "\n",
    "\n",
    "callbacks = [tensor_board, model_checkpoint, csv_logger, early_stop, reduce_lr]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "459/458 [==============================] - 2837s 6s/step - loss: 5.3098 - acc: 0.0093 - val_loss: 5.2534 - val_acc: 0.0123\n",
      "\n",
      "Epoch 00001: val_acc improved from -inf to 0.01227, saving model to model/model.01-0.01.hdf5\n",
      "Epoch 2/6\n",
      "459/458 [==============================] - 2677s 6s/step - loss: 5.2601 - acc: 0.0103 - val_loss: 7.9674 - val_acc: 0.0098\n",
      "\n",
      "Epoch 00002: val_acc did not improve from 0.01227\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "Epoch 3/6\n",
      "459/458 [==============================] - 2654s 6s/step - loss: 5.2052 - acc: 0.0121 - val_loss: 5.1659 - val_acc: 0.0245\n",
      "\n",
      "Epoch 00003: val_acc improved from 0.01227 to 0.02454, saving model to model/model.03-0.02.hdf5\n",
      "Epoch 4/6\n",
      "459/458 [==============================] - 2649s 6s/step - loss: 5.1897 - acc: 0.0144 - val_loss: 5.2043 - val_acc: 0.0160\n",
      "\n",
      "Epoch 00004: val_acc did not improve from 0.02454\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "Epoch 5/6\n",
      "459/458 [==============================] - 2649s 6s/step - loss: 5.1760 - acc: 0.0159 - val_loss: 5.1448 - val_acc: 0.0172\n",
      "\n",
      "Epoch 00005: val_acc did not improve from 0.02454\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "Epoch 6/6\n",
      "459/458 [==============================] - 2646s 6s/step - loss: 5.1726 - acc: 0.0150 - val_loss: 5.1910 - val_acc: 0.0209\n",
      "\n",
      "Epoch 00006: val_acc did not improve from 0.02454\n",
      "\n",
      "Epoch 00006: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f917ab59668>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fine tune the model\n",
    "transfer_model.fit_generator(\n",
    "    generator = train_generator,\n",
    "    steps_per_epoch = n_train_samples / batch_size,\n",
    "    validation_data = valid_generator,\n",
    "    validation_steps = n_valid_samples / batch_size,\n",
    "    epochs = 6,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grabenv",
   "language": "python",
   "name": "grabenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
