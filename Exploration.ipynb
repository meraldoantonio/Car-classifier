{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# For folder processing\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import tarfile\n",
    "import urllib.request\n",
    "\n",
    "# For Image Processing and Display\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline \n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# For Visualization\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected = True)\n",
    "from jupyter_plotly_dash import JupyterDash\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "# For data processing\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# For Training Image Classification Model\n",
    "import keras\n",
    "import os.path\n",
    "from keras.models import load_model\n",
    "from keras.applications.resnet50 import preprocess_input, decode_predictions, ResNet50\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import to_categorical\n",
    "from keras import optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_dataset(url, target_folder):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        - Creates a subdirectory \"./Data\" in the current working directory if it doesn't exist already\n",
    "        - Downloads the dataset into the newly created folder\n",
    "        \n",
    "    Arguments:\n",
    "        - url: (str) URL of dataset\n",
    "        - target_folder: (str) relative path of target folder\n",
    "        \n",
    "    Return:\n",
    "        - A \"./Data\" folder containing the zipped dataset\n",
    "    \"\"\"\n",
    "    # Path to downloaded file\n",
    "    target_file = target_folder + \"/\" + url.split(\"/\")[-1]\n",
    "    \n",
    "    # If the dataset has already been downloaded, terminate function\n",
    "    if os.path.exists(target_file):\n",
    "        print(\"Data has already been downloaded at '{}'.\".format(target_file))\n",
    "        return\n",
    "    \n",
    "    # If target folder doesn't exist yet, create it\n",
    "    if not os.path.exists(target_folder):\n",
    "        os.mkdir(target_folder.split(\"/\")[-1])\n",
    "        print(\"Created a new folder at '{}'.\".format(target_folder))\n",
    "        \n",
    "    # Downloading the dataset\n",
    "    print(\"Downloading dataset from '{}', please wait...\".format(url))\n",
    "    urllib.request.urlretrieve(url, target_file)  \n",
    "    print(\"File successfully downloaded to '{}''.\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_1 = \"http://imagenet.stanford.edu/internal/car196/cars_train.tgz\" \n",
    "target_folder = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matlab file conntaining that maps the label and full name of the car\n",
    "original_dict_metadata = loadmat('devkit/cars_meta.mat')\n",
    "#dict_meta = dictionary containing metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_idx_carname = {int(index+1):classname[0] for index, classname in enumerate(original_dict_metadata[\"class_names\"][0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_idx_carname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "carname_list = dict_idx_carname.values()\n",
    "dict_brand_count = defaultdict(int)\n",
    "for carname in carname_list:\n",
    "    brand = carname.split(\" \")[0]\n",
    "    dict_brand_count[brand] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load matlab file\n",
    "original_dict_traindata = loadmat('devkit/cars_train_annos.mat')\n",
    "\n",
    "master_dict_traindata = {}\n",
    "# Annotations = {\"fname\": {\"bbox_xmin\": 12, \"bbox_xmax\": 13, \"bbox_y1\": , \"bbox_y2\"}}\n",
    "\n",
    "master_dict_traindata = {image[5][0]:{\"bbox_xmin\": image[0][0][0], \"bbox_xmin\": image[0][0][0], \"bbox_xmax\": image[1][0][0],\"bbox_ymin\": image[2][0][0],\"bbox_ymax\": image[3][0][0],\"classnumber\": image[4][0][0], \"classname\": dict_idx_carname[image[4][0][0]]} for image in original_dict_traindata[\"annotations\"][0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_to_dictionary(image_path = \"./data\", dictionary = master_dict_traindata):\n",
    "    \"\"\"\n",
    "    Function: \n",
    "        -loads images from the target folder\n",
    "        -resizes and preprocesses the images \n",
    "        -append the original and preprocssed images, file names and labels into a \"dataset\"\n",
    "    Arguments: \n",
    "        -folder (str): the directory containing the images\n",
    "        -label (str): the class of images\n",
    "        -width (int): desired width after resizing\n",
    "        -height (int): desired height after resizing\n",
    "    Returns: \n",
    "        -dataset (list): list of tuples: (nd.array of original image, nd.array of preprocessed image, image name, image label)\n",
    "    \"\"\"\n",
    "    image_list = os.listdir(image_path)\n",
    "    \n",
    "    for index, filename in enumerate(image_list):\n",
    "        try:\n",
    "            img = Image.open(os.path.join(image_path,filename))\n",
    "            img_np = np.array(img)\n",
    "            dictionary[filename][\"np_image\"] = img_np\n",
    "            #dictionary[filename][\"preprocessed_image\"] = preprocess_input(img_np)\n",
    "        except:\n",
    "            continue\n",
    "    return dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_dict_traindata = load_images_to_dictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.DataFrame.from_dict(data = master_dict_traindata, orient = \"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.loc[\"00001.jpg\", \"classname\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image_in_dataframe(dataframe = df_train, idx = 0):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        - shows an image from the dataset and its label\n",
    "    Arguments:\n",
    "        - dataset (list): list of tuples: (nd.array of original image, nd.array of preprocessed image, image name, image label)\n",
    "    Returns:\n",
    "         none, but the function will show the original and preprocessedimage, its name and its label\n",
    "    \"\"\"\n",
    "    \n",
    "    filename = list(dataframe.index)[idx]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(9,5))\n",
    "    ax.imshow(df_train.loc[filename, 'np_image'], interpolation='nearest')\n",
    "    ax.set_title(\"Your original image after resizing:\")\n",
    "    plt.show()\n",
    "    print(f\"Image file name: {filename}\")\n",
    "    print(f\"Image class: {df_train.loc[filename, 'classname']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = interact(show_image_in_dataframe, dataframe = fixed(df_train), idx=widgets.IntSlider(min=0,max=len(master_dict_traindata)-1,step=1,value=50), continous_update = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'defaultdict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5ffb14cb82d7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdict_classname_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdatapoint\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmaster_dict_traindata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mclassname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatapoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"classname\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdict_classname_count\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclassname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'defaultdict' is not defined"
     ]
    }
   ],
   "source": [
    "dict_classname_count = defaultdict(int)\n",
    "for datapoint in master_dict_traindata.values():\n",
    "    classname = datapoint[\"classname\"]\n",
    "    dict_classname_count[classname] += 1\n",
    "\n",
    "\n",
    "trace = go.Bar(x = list(dict_classname_count.keys()), y = list(dict_classname_count.values()))\n",
    "data = [trace]\n",
    "layout = go.Layout(title = \"Count Per Class\", xaxis = {\n",
    "        'categoryorder': 'array',\n",
    "        'categoryarray': [x for _, x in sorted(zip(list(dict_classname_count.values()), list(dict_classname_count.keys())))]\n",
    "        },\n",
    "                  )\n",
    "\n",
    "\n",
    "figure = go.Figure(data = data, layout = layout)\n",
    "iplot(figure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_resnet50_model():\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        - If the ResNet50 model isn't already saved, the function will download the model, save it to ./model/ResNet50.h5 and return it\n",
    "        - If model is already saved, the function will simply return the model\n",
    "    Return:\n",
    "        - The original ResNet50 model\n",
    "    \"\"\"\n",
    "    model_path = \"./model/ResNet50.h5\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Retrieving saved model from {model_path}...\")\n",
    "        model = load_model(model_path)\n",
    "        print(\"Saved model retrieved!\")\n",
    "        return model\n",
    "    else:\n",
    "        from keras.applications.resnet50 import ResNet50\n",
    "        print(\"Downloading model...\")\n",
    "        os.makedirs (\"./model\")\n",
    "        model = ResNet50(weights='imagenet')\n",
    "        model.save(model_path)\n",
    "        print(f\"Model retrieved and saved in {model_path}\")\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50 = load_resnet50_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet50.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'resnet50' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-be1871a16c08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;31m# Grab a sample image from the dataset and show it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"==================================\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resnet50' is not defined"
     ]
    }
   ],
   "source": [
    "def test_model(model = resnet50, dataframe = df_train, idx = 0):\n",
    "    \n",
    "    \n",
    "    # Grab a sample image from the dataset and show it\n",
    "    print(\"==================================\")\n",
    "    print(\"Image:\")\n",
    "    show_image_in_dataframe(dataframe, idx)\n",
    "    print(\"==================================\")\n",
    "    \n",
    "    # Get the numpy array of the sample image\n",
    "    \n",
    "    filename = list(dataframe.index)[idx]\n",
    "    \n",
    "    \n",
    "    \n",
    "    sample_image = df_train.loc[filename, 'np_image'].copy()\n",
    "    sample_image = np.resize(sample_image,(224, 224, 3))\n",
    "    sample_image = preprocess_input(sample_image)\n",
    "    sample_image = np.expand_dims(sample_image, axis=0)\n",
    "\n",
    "\n",
    "    # Input it to the chosen model\n",
    "    preds = model.predict(sample_image)\n",
    "    \n",
    "    # Get the top 5 prediction classes and their corresponding probabilities\n",
    "    prediction_classes = [item[1] for item in decode_predictions(preds, top=5)[0]]\n",
    "    prediction_probabilities = [item[2]*100 for item in decode_predictions(preds, top=5)[0]]\n",
    "    \n",
    "    # Show these probabilities as interactive bar charts\n",
    "    trace = go.Bar(x = prediction_classes, y = prediction_probabilities)\n",
    "    data = [trace]\n",
    "    layout =  go.Layout(title = \"Probabilities of top 5 predictions\", xaxis=dict(title= 'Car class',\n",
    "                                 tickfont= dict(family='Old Standard TT, serif',\n",
    "                                                                              size=15,\n",
    "                                                                              color='black')),\n",
    "                        yaxis=dict(title= 'Probability (%)', hoverformat = '.2f'),\n",
    "                        autosize=True,\n",
    "                        width=600,\n",
    "                        height=400)\n",
    "    figure = go.Figure(data = data, layout = layout)\n",
    "    iplot(figure)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7eec2d854585>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test_model' is not defined"
     ]
    }
   ],
   "source": [
    "test_model(model = resnet50, dataframe = df_train, idx = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = interact(test_model, model = fixed(resnet50), dataframe = fixed(df_train), idx=widgets.IntSlider(min=0,max=len(df_train)-1,step=1,value=50), continous_update = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_untrained_transfer_model():\n",
    "    \"\"\"\n",
    "    If model isn't saved - download model, save it to current directory and return it\n",
    "    If model already exists, simply return the model\n",
    "    \"\"\"\n",
    "    model_path = \"./model/Untrained_transfer.h5\"\n",
    "    if os.path.exists(model_path):\n",
    "        print(f\"Retrieving saved model from {model_path}\")\n",
    "        untrained_transfer_model = load_model(model_path)\n",
    "        print(\"Saved model retrieved!\")\n",
    "        return untrained_transfer_model\n",
    "    else:\n",
    "        ## Build model\n",
    "        print(\"Downloading and building model...\")\n",
    "        untrained_transfer_model = Sequential()\n",
    "        untrained_transfer_model.add(ResNet50(include_top = False, pooling = \"avg\", weights = \"imagenet\"))\n",
    "        untrained_transfer_model.add(Dense(512, activation = \"relu\"))\n",
    "        untrained_transfer_model.add(Dropout(0.5))\n",
    "        untrained_transfer_model.add(Dense(512, activation = \"relu\"))\n",
    "        untrained_transfer_model.add(Dropout(0.5))\n",
    "        untrained_transfer_model.add(Dense(2, activation = \"softmax\"))\n",
    "        \n",
    "        untrained_transfer_model.layers[0].trainable = False\n",
    "        \n",
    "        ## Save model\n",
    "        print(f\"Model built and saved in {model_path}\")\n",
    "        untrained_transfer_model.save(model_path)\n",
    "        return untrained_transfer_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and building model...\n",
      "Model built and saved in ./model/Untrained_transfer.h5\n"
     ]
    }
   ],
   "source": [
    "transfer_model = load_untrained_transfer_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 2048)              23587712  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               1049088   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 24,900,482\n",
      "Trainable params: 1,312,770\n",
      "Non-trainable params: 23,587,712\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "transfer_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "transfer_model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(np_image):\n",
    "    resized_np_image = np.resize(np_image,(224,224,3))\n",
    "    preprocessed_np_image = preprocess_input(resized_np_image)\n",
    "    return preprocessed_np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train[\"preprocessed_np_image\"] = df_train[\"np_image\"].apply(lambda x: preprocess_image(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen = ImageDataGenerator(rotation_range=20.,\n",
    "                                    width_shift_range=0.1,\n",
    "                                    height_shift_range=0.1,\n",
    "                                    zoom_range=0.2,\n",
    "                                    horizontal_flip=True,\n",
    "                                    validation_split = 0.2,\n",
    "                                    preprocessing_function = preprocess_image)\n",
    "\n",
    "    \n",
    "directory_iterator = train_data_gen.flow_from_directory(\"./data\", \n",
    "                                                        (224, 224), \n",
    "                                                        batch_size=2,\n",
    "                                                        seed = 42,\n",
    "                                                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Car_A': 0, 'Car_B': 1}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "directory_iterator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "2/2 [==============================] - 0s 158ms/step - loss: 0.1473 - acc: 1.0000\n",
      "Epoch 2/2\n",
      "2/2 [==============================] - 0s 139ms/step - loss: 1.7351 - acc: 0.2500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02d0939ba8>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transfer_model.fit_generator(\n",
    "    directory_iterator,\n",
    "    steps_per_epoch=2,\n",
    "    epochs=2,\n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.stack([image for image in df_train[\"preprocessed_np_image\"]])\n",
    "print(f\"Shape of training set: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the labels from our six datasets\n",
    "encoder = LabelBinarizer()\n",
    "y = encoder.fit_transform(df_train[\"classnumber\"])\n",
    "print(f\"Shape of label set: {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_epoch = 20\n",
    "filepath=\"./model/trained_model-{epoch:02d}-{val_acc:.2f}.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')\n",
    "callbacks_list = [checkpoint]\n",
    "history = transfer_model.fit(x = X, y = y, validation_split = 0.1, epochs = max_epoch, callbacks = callbacks_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "grabenv",
   "language": "python",
   "name": "grabenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
